{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named cv2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-19ed8b48fd1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named cv2"
     ]
    }
   ],
   "source": [
    "###########\n",
    "# IMPORTS #\n",
    "###########\n",
    "%matplotlib inline\n",
    "\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##########\n",
    "# LABELS #\n",
    "##########\n",
    "\n",
    "LABELS = ['positive', 'neutral', 'negative']\n",
    "label_dict = {}\n",
    "with open('labels.csv', 'r', newline='') as labels:\n",
    "    label_reader = csv.reader(labels, delimiter=' ', quotechar='|')\n",
    "    next(label_reader)\n",
    "    for row in label_reader:\n",
    "        entry = row[0].split(',')\n",
    "        label_dict[entry[0]] = entry[1].lower()\n",
    "        \n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# FRAME SPLIT #\n",
    "###############\n",
    "\n",
    "curr_dir = os.getcwd()\n",
    "vid_clips_2020 = curr_dir + '/example_clips/'\n",
    "\n",
    "def preprocess_frame(frame, crop_pad=5):\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    eyes_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    faces_detected = face_cascade.detectMultiScale(frame, scaleFactor=1.1, minNeighbors=5)\n",
    "    # if not 1 face, disregard this frame\n",
    "    if len(faces_detected) != 1:\n",
    "        return False\n",
    "    \n",
    "    (x, y, w, h) = faces_detected[0]\n",
    "    # crop the frame around the face\n",
    "    frame_cropped = frame[y-crop_pad+1:y+h+crop_pad, x-crop_pad+1:x+w+crop_pad]\n",
    "    return frame_cropped\n",
    "\n",
    "\n",
    "def preprocess_clip(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".mp4\"):\n",
    "            video = directory + filename\n",
    "            vidcap = cv2.VideoCapture(video)\n",
    "            success,image = vidcap.read()\n",
    "            count = 0\n",
    "            new_dir = '{}/data/{}/'.format(curr_dir, label_dict[filename])\n",
    "            while success:\n",
    "                frame_file = '{}{}_frame{}_{}.jpg'.format(new_dir, os.path.splitext(filename)[0], count, label_dict[filename])\n",
    "                if not os.path.exists(os.path.dirname(frame_file)):\n",
    "                    try:\n",
    "                        os.makedirs(os.path.dirname(frame_file))\n",
    "                    except OSError as exc: # Guard against race condition\n",
    "                        if exc.errno != errno.EEXIST:\n",
    "                            raise\n",
    "                \n",
    "                new_frame = preprocess_frame(image)\n",
    "                if (type(new_frame) == np.ndarray):\n",
    "                    cv2.imwrite(frame_file, new_frame)     # save frame as JPEG file\n",
    "                else:\n",
    "                    break # once you stop detecting one face, don't take more frames\n",
    "                success,image = vidcap.read()\n",
    "                count += 1\n",
    "            print('Split video', video)\n",
    "        else:\n",
    "            continue\n",
    "preprocess_clip(vid_clips_2020)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##################\n",
    "# FACE DETECTION #\n",
    "##################\n",
    "\n",
    "face_coordinates = {}\n",
    "eye_coordinates = {}\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eyes_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "# for batch preprocessing\n",
    "def find_face(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".mp4\"):\n",
    "            frame_dir = curr_dir + '/preprocessed/' + os.path.splitext(filename)[0] + '/'\n",
    "            for frame in os.listdir(frame_dir):\n",
    "                frame_name = frame_dir + frame\n",
    "                img = cv2.imread(frame_name)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                faces_detected = face_cascade.detectMultiScale(img, scaleFactor=1.1, minNeighbors=5)\n",
    "                if len(faces_detected) == 1:\n",
    "                    (x, y, w, h) = faces_detected[0]\n",
    "                    face_coordinates[frame_name] = (x, y, w, h)\n",
    "                    \n",
    "                    \n",
    "#                     eyes = eyes_cascade.detectMultiScale(img[y:y+h, x:x+w])\n",
    "#                     eye_coordinates[frame_name] = [(ex, ey, ew, eh) for (ex, ey, ew, eh) in eyes]\n",
    "#                     for (ex, ey, ew, eh) in eyes:\n",
    "#                         cv2.rectangle(img, (x+ex, y+ey), (x+ex+ew, y+ey+eh), (255, 255, 255), 1)\n",
    "#                         plt.imshow(img)\n",
    "#                         plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#################\n",
    "# FACE CROPPING #\n",
    "#################\n",
    "\n",
    "def crop_faces(padding=5):\n",
    "    for pic_name in face_coordinates:\n",
    "        (x, y, w, h) = face_coordinates[pic_name]\n",
    "        img = cv2.imread(pic_name)\n",
    "        try:\n",
    "            # NOTE: this throws an error for some reason but it also does the cropping\n",
    "            # so not sure what's going on there\n",
    "            cv2.imwrite(pic_name, img[y-padding+1:y+h+padding, x-padding+1:x+w+padding])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "crop_faces()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# for single frame preprocessing (takes in an already read image frame)\n",
    "def preprocess_frame(frame, crop_pad=5):\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    eyes_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    faces_detected = face_cascade.detectMultiScale(frame, scaleFactor=1.1, minNeighbors=5)\n",
    "    # if not 1 face, disregard this frame\n",
    "    if len(faces_detected) != 1:\n",
    "        return False\n",
    "    \n",
    "    (x, y, w, h) = faces_detected[0]\n",
    "    # crop the frame around the face\n",
    "    frame_cropped = frame[y-crop_pad+1:y+h+crop_pad, x-crop_pad+1:x+w+crop_pad]\n",
    "    return frame_cropped\n",
    "\n",
    "\n",
    "# vs = cv2.VideoCapture('2020/VideoClips/buttigieg_1_2.mp4')\n",
    "# while True:\n",
    "#     (grabbed, frame) = vs.read()\n",
    "#     if not grabbed:\n",
    "#         break\n",
    "        \n",
    "#     new_frame = preprocess_frame(frame)\n",
    "#     if (type(new_frame) == np.ndarray):\n",
    "#         plt.imshow(new_frame)\n",
    "#         plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
